// const {GoogleGenAI} = require('@google/genai');
import './proxy-setup.js'; // Load proxy setup first
import { GoogleGenAI } from '@google/genai';
import fs from 'fs/promises';
import path from 'path';
import dotenv from 'dotenv';
dotenv.config();
const GOOGLE_CLOUD_PROJECT = process.env.GOOGLE_CLOUD_PROJECT;
const GOOGLE_CLOUD_LOCATION = process.env.GOOGLE_CLOUD_LOCATION || 'global';
const errorKey = []
// æ”¯æŒå¤šä¸ª API keyï¼Œç”¨é€—å·åˆ†éš”
const GEMINI_API_KEYS = process.env.GEMINI_API_KEY
  ? process.env.GEMINI_API_KEY.split(',').map(key => key.trim()).filter(key => key.length > 0)
  : [];

if (GEMINI_API_KEYS.length === 0) {
  console.error('âŒ é”™è¯¯: æœªæ‰¾åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡');
  process.exit(1);
}

// è¯·æ±‚é—´éš”ï¼ˆæ¯«ç§’ï¼‰ï¼Œä»…é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼šREQUEST_DELAY_MS
const DEFAULT_REQUEST_DELAY_MS = 60000;
const REQUEST_DELAY_MS = (() => {
  const v = parseInt(process.env.REQUEST_DELAY_MS, 10);
  return (!Number.isNaN(v) && v >= 0) ? v : DEFAULT_REQUEST_DELAY_MS;
})();

import Logger from './lib/logger.js';
import ProcessedTracker from './lib/tracker.js';

const logger = new Logger();
const tracker = new ProcessedTracker();

async function generateText(
  ytUrl,
  projectId = GOOGLE_CLOUD_PROJECT,
  location = GOOGLE_CLOUD_LOCATION
) {
  const prompt = `è¯·æ ¹æ®è§†é¢‘åˆ¤æ–­å†…å®¹æ˜¯å¦åŒ…å«åšèœæ•™ç¨‹ï¼Œå¦‚æœéåšèœè§†é¢‘ï¼Œå°±ç”Ÿæˆä¸€åˆ™åŒ…æ‹¬æ ‡é¢˜çš„æ‘˜è¦ã€‚å¦‚æœæ˜¯åšèœè§†é¢‘åˆ™ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„é£Ÿè°±ï¼Œå¿…é¡»ä¸¥æ ¼ä½¿ç”¨ Markdown æ ¼å¼ã€‚
è¦æ±‚ï¼š
1. ç¬¬ä¸€è¡Œå¿…é¡»æ˜¯é£Ÿè°±åç§°ï¼ˆä½¿ç”¨ # ä¸€çº§æ ‡é¢˜ï¼Œå­—æ•°ä¸è¶…è¿‡10ä¸ªæ±‰å­—ï¼‰ã€‚
2. åŒ…å«"é£Ÿæ"éƒ¨åˆ†ï¼ˆä½¿ç”¨æ— åºåˆ—è¡¨ï¼‰ã€‚
3. åŒ…å«"æ­¥éª¤"éƒ¨åˆ†ï¼ˆä½¿ç”¨æœ‰åºåˆ—è¡¨ï¼‰ã€‚
4. ç›´æ¥è¾“å‡º Markdown å†…å®¹ï¼Œä¸¥ç¦ä½¿ç”¨ä»£ç å—ç¬¦å·ï¼ˆ\`\`\`ï¼‰åŒ…è£¹ã€‚
5. ä¸è¦åŒ…å«ä»»ä½•å¤šä½™çš„å¯¹è¯ã€å¼€åœºç™½æˆ–ç»“æŸè¯­ã€‚
6. é£Ÿæå’Œè°ƒæ–™çš„æ•°é‡æ ¹æ®è§†é¢‘å†…å®¹æ¥ä¼°ç®—ï¼Œæ˜ç¡®ä¸€ç‚¹ã€‚
7. æœ€åè¦åšæŠ€æœ¯æ€»ç»“ï¼Œä»¥åŠç‚¹è¯„è¿™é“èœçš„çµé­‚é…æ–™ã€‚
`;

  const ytVideo = {
    fileData: {
      fileUri: ytUrl,
      mimeType: 'video/mp4',
    },
  };

  // ä»ç¯å¢ƒå˜é‡è¯»å–æ¨¡å‹åï¼Œé»˜è®¤ä½¿ç”¨ gemini-2.5-flash
  const GEMINI_MODEL = process.env.GEMINI_MODEL || 'gemini-2.5-flash';

  // å°è¯•æ‰€æœ‰å¯ç”¨çš„ API key
  for (let i = 0; i < GEMINI_API_KEYS.length; i++) {
    const apiKey = GEMINI_API_KEYS[i];
    if (errorKey.includes(apiKey)) {
      continue;
    }
    const client = new GoogleGenAI({
      apiKey: apiKey,
    });

    try {
      const response = await client.models.generateContent({
        model: GEMINI_MODEL,
        contents: [ytVideo, prompt],
      });
      if (response.text === undefined || response.text === null || response.text === '') { return null }
      console.log(`Response for ${ytUrl} generated using API key ${i + 1}/${GEMINI_API_KEYS.length} with model ${GEMINI_MODEL}.`);
      let text = response.text;
      // Clean up: remove markdown code block delimiters if present
      if (text.startsWith('```markdown')) {
        text = text.replace(/^```markdown\s*/, '').replace(/\s*```$/, '');
      } else if (text.startsWith('```')) {
        text = text.replace(/^```\s*/, '').replace(/\s*```$/, '');
      }

      return text;
    } catch (error) {
      const errorMsg = `âŒ API key ${i + 1}/${GEMINI_API_KEYS.length} ä½¿ç”¨æ¨¡å‹ ${GEMINI_MODEL} å¤„ç† ${ytUrl} æ—¶å‡ºé”™: ${error.message || error}`;
      await logger.error(errorMsg);

      // console.log("error-------type--->", error.message)


      if (`${error.message || error}`.indexOf(`"code":429`) > -1) {
        errorKey.push(apiKey);
        // å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ª keyï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
        if (i < GEMINI_API_KEYS.length - 1) {
          await logger.log(`ğŸ”„ åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API key (${i + 2}/${GEMINI_API_KEYS.length})...`);
          continue;
        }
      }
      return null;
    }
  }

  // æ‰€æœ‰ key éƒ½å¤±è´¥
  await logger.error(`âŒ æ‰€æœ‰ API key éƒ½å·²å°è¯•æˆ–æ— æ³•å¤„ç† ${ytUrl}`);
  return null;
}

function sanitizeFilename(filename) {
  // Replace invalid filename characters with underscore
  return filename.replace(/[<>:"/\\|?*]/g, '_').trim();
}

function extractTitleFromMarkdown(content) {
  if (!content) return null;

  // Try to find the first Markdown header (# Title)
  const headerMatch = content.match(/^#\s+(.+)$/m);
  if (headerMatch) {
    return headerMatch[1].trim();
  }

  // Fallback: Find the first non-empty line that isn't a code block
  const lines = content.split('\n');
  for (const line of lines) {
    const trimmed = line.trim();
    if (trimmed && !trimmed.startsWith('```')) {
      // Remove common markdown formatting chars from the start if present (like ** or *)
      return trimmed.replace(/^[*#> -]+/, '').trim();
    }
  }

  return null;
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function main() {
  await logger.init();
  await tracker.load();


  await logger.log(`Using REQUEST_DELAY_MS=${REQUEST_DELAY_MS}ms`);



  // Parse CLI args or environment variables for input
  const argv = process.argv.slice(2);
  let inputArg = null;
  for (let i = 0; i < argv.length; i++) {
    const a = argv[i];
    if (a.startsWith('--input=')) {
      inputArg = a.split('=')[1];
      break;
    }
    if (a === '--input' || a === '-i') {
      if (i + 1 < argv.length) {
        inputArg = argv[i + 1];
        break;
      }
    }
    // first non-flag positional argument
    if (!a.startsWith('-') && !inputArg) {
      inputArg = a;
      break;
    }
  }

  const envInput = process.env.INPUT_JSON || process.env.JSON_FILE || process.env.JSON_DIR;
  const specified = inputArg || envInput;

  // Determine whether specified path is file or dir. Defaults:
  // - if specified and is file -> process single file
  // - if specified and is dir -> process all *_urls.json in dir
  // - if not specified -> prefer './out/out_urls.json' if exists, otherwise './out' directory
  let targetFiles = [];

  const tryStat = async p => {
    try {
      return await fs.stat(p);
    } catch (e) {
      return null;
    }
  };

  if (specified) {
    const sstat = await tryStat(specified);
    if (sstat && sstat.isFile()) {
      targetFiles = [specified];
    } else if (sstat && sstat.isDirectory()) {
      const entries = await fs.readdir(specified, { withFileTypes: true });
      targetFiles = entries.filter(e => e.isFile() && e.name.endsWith('_urls.json')).map(e => path.join(specified, e.name));
    } else {
      // path doesn't exist as given; if it ends with .json treat as file path (may be created later)
      if (specified.endsWith('.json')) {
        targetFiles = [specified];
      } else {
        // treat as directory path, attempt to read
        try {
          const entries = await fs.readdir(specified, { withFileTypes: true });
          targetFiles = entries.filter(e => e.isFile() && e.name.endsWith('_urls.json')).map(e => path.join(specified, e.name));
        } catch (e) {
          // fallback to ./out
          targetFiles = [];
        }
      }
    }
  }

  if (!specified) {
    // prefer single default file if present
    const defaultFile = './out/out_urls.json';
    const dfStat = await tryStat(defaultFile);
    if (dfStat && dfStat.isFile()) {
      targetFiles = [defaultFile];
    } else {
      // scan out directory
      const defaultDir = './out';
      const dStat = await tryStat(defaultDir);
      if (dStat && dStat.isDirectory()) {
        const entries = await fs.readdir(defaultDir, { withFileTypes: true });
        targetFiles = entries.filter(e => e.isFile() && e.name.endsWith('_urls.json')).map(e => path.join(defaultDir, e.name));
      }
    }
  }

  if (targetFiles.length === 0) {
    await logger.log(`No target *_urls.json files found to process. Provide --input <file|dir> or place files under ./out`);
    return;
  }

  await logger.log(`Processing ${targetFiles.length} file(s):`);
  for (const f of targetFiles) await logger.log(`  - ${f}`);

  let successCount = 0;
  let failureCount = 0;
  let skippedCount = 0;
  const failedUrls = [];
  const skippedUrls = [];

  await logger.log(`Previously processed: ${tracker.processed.size}`);

  for (const jsonFilePath of targetFiles) {
    await logger.log(`\nReading URLs from ${jsonFilePath}...`);
    const dirPath = path.dirname(jsonFilePath);
    let fileContent;
    try {
      fileContent = await fs.readFile(jsonFilePath, 'utf-8');
    } catch (e) {
      await logger.error(`Failed to read ${jsonFilePath}: ${e.message || e}`);
      continue;
    }
    let urls;
    try {
      urls = JSON.parse(fileContent);
    } catch (e) {
      await logger.error(`Failed to parse JSON in ${jsonFilePath}: ${e.message || e}`);
      continue;
    }
    if (!Array.isArray(urls)) {
      await logger.error(`JSON content in ${jsonFilePath} is not an array of URLs, skipping.`);
      continue;
    }

    await logger.log(`Total URLs in file: ${urls.length}`);

    for (const url of urls) {
      if (errorKey.length === GEMINI_API_KEYS.length) {
        await logger.error(`All API keys have been rate-limited. Stopping processing.`);
        break;
      }
      // Skip if already processed
      if (tracker.has(url)) {
        await logger.log(`â­ï¸  Skipping (already processed): ${url}`);
        skippedCount++;
        skippedUrls.push(url);
        continue;
      }

      await logger.log(`\nğŸ“ Processing: ${url}`);
      const content = await generateText(url);

      if (content) {
        let fileName;
        const extractedTitle = extractTitleFromMarkdown(content);

        if (extractedTitle) {
          fileName = `${sanitizeFilename(extractedTitle)}.md`;
        } else {
          // Fallback to video ID
          let videoId = 'unknown';
          try {
            const urlObj = new URL(url);
            videoId = urlObj.searchParams.get('v') || 'unknown';
          } catch (e) {
            const match = url.match(/[?&]v=([^&]+)/);
            if (match) videoId = match[1];
          }
          fileName = `Video_${videoId}.md`;
          await logger.warn(`Could not extract title from content, using fallback filename: ${fileName}`);
        }
        fileName.length > 25 && (fileName = fileName.slice(0, 20) + '.md'); // ensure filename length limit
        const filePath = path.join(dirPath, fileName);
        await fs.writeFile(filePath, content);
        await logger.log(`âœ… Saved: ${filePath}`);
        successCount++;
        tracker.add(url); // Mark as processed
        // Save tracker after processing each successful URL (incremental)
        await tracker.save();
      } else {
        await logger.error(`Failed to generate recipe for: ${url}`);
        failureCount++;
        failedUrls.push(url);
        tracker.add(url);
        // Do NOT mark as processed if generation failed, so we can retry next time
      }
      // ç­‰å¾…é…ç½®çš„é—´éš”åå†å¤„ç†ä¸‹ä¸€ä¸ªï¼ˆæ¯«ç§’ï¼‰
      if (REQUEST_DELAY_MS > 0 && errorKey.length < GEMINI_API_KEYS.length) {
        await logger.log(`â±ï¸  Waiting ${REQUEST_DELAY_MS}ms before next request...`);
        await sleep(REQUEST_DELAY_MS);
      }
    }
  }



  // Summary log
  const separator = '='.repeat(70);
  await logger.log('\n' + separator);
  await logger.log('ğŸ“Š Processing Summary');
  await logger.log(separator);
  await logger.log(`âœ… Successful: ${successCount}`);
  await logger.log(`âŒ Failed: ${failureCount}`);
  await logger.log(`â­ï¸  Skipped (already processed): ${skippedCount}`);
  await logger.log(`ğŸ“ˆ Total: ${successCount + failureCount + skippedCount}`);

  if (failedUrls.length > 0) {
    await logger.log('\nâŒ Failed URLs (will retry next run):');
    failedUrls.forEach((url, index) => {
      logger.log(`   ${index + 1}. ${url}`);
    });
  }
  await logger.log(separator);
  await logger.log(`\nâœ¨ Log file saved to: ${logger.logPath}`);
  await logger.log(`ğŸ“‹ Processed records saved to: ${tracker.trackerFile}\n`);
}

main().catch(async (error) => {
  await logger.error(`Unhandled error: ${error.message || error}`);
  try {
    await tracker.save();
    await logger.log('ğŸ’¾ Tracker saved after crash');
  } catch (e) {
    console.error('Failed to save tracker after crash:', e);
  }
  process.exit(1);
});

